{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import Union, Any, Tuple, List, Dict\n",
    "from collections import defaultdict\n",
    "from jaxtyping import Float\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import einops\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     trust_remote_code=True,\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_layers = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orthogonalized_matrix(\n",
    "    matrix: Float[torch.Tensor, \"... d_model\"], vec: Float[torch.Tensor, \"d_model\"]\n",
    ") -> Float[torch.Tensor, \"... d_model\"]:\n",
    "    print(f\"Matrix shape: {matrix.shape}\")\n",
    "    print(f\"Vector shape: {vec.shape}\")\n",
    "\n",
    "    original_shape = matrix.shape\n",
    "\n",
    "    # Reshape matrix if necessary\n",
    "    if matrix.shape[-1] != vec.shape[0]:\n",
    "        matrix = matrix.transpose(-1, -2)\n",
    "\n",
    "    # Ensure vec is a column vector\n",
    "    vec_col = vec.view(-1, 1)\n",
    "\n",
    "    # Calculate projection\n",
    "    proj = einops.einsum(matrix, vec_col, \"... d_model, d_model single -> ... single\") * vec\n",
    "\n",
    "    # Subtract projection from matrix\n",
    "    result = matrix - proj\n",
    "\n",
    "    # Reshape result back to original shape if it was transposed\n",
    "    if result.shape != original_shape:\n",
    "        result = result.transpose(-1, -2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orthogonalized_matrix_2(matrix: Float[torch.Tensor, \"m n\"], vec: Float[torch.Tensor, \"m\"]) -> Float[torch.Tensor, \"m n\"]:\n",
    "    print(f\"Matrix shape: {matrix.shape}\")\n",
    "    print(f\"Vector shape: {vec.shape}\")\n",
    "\n",
    "    # Calculate projection using modified einsum\n",
    "    proj = einops.einsum(matrix, vec, \"m n, m -> n\") * vec.unsqueeze(1)\n",
    "\n",
    "    # Subtract projection from matrix\n",
    "    return matrix - proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_layers(layer_rankings: List[Dict] = None, layers: List[int] = None, attn_output: bool = True, mlp: bool = True):\n",
    "    layers = layers or list(range(1, len(model.model.layers)))\n",
    "    if attn_output or mlp:\n",
    "        modified = True\n",
    "\n",
    "    for refusal_direction in layer_rankings:\n",
    "        refusal_direction = refusal_direction[\"refusal_direction\"]\n",
    "\n",
    "        for layer in tqdm(layers, leave=False):\n",
    "            block = model.model.layers[layer]\n",
    "            if refusal_direction.device != model.device:\n",
    "                refusal_direction = refusal_direction.to(model.device)\n",
    "            if attn_output:\n",
    "                block.self_attn.o_proj.weight.data = get_orthogonalized_matrix(block.self_attn.o_proj.weight.data, refusal_direction)\n",
    "                modified_layers[\"attention_output_layer\"].append(layer)\n",
    "            if mlp:\n",
    "                block.mlp.down_proj.weight.data = get_orthogonalized_matrix(block.mlp.down_proj.weight.data, refusal_direction)\n",
    "                modified_layers[\"mlp\"].append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ablate_layers([{\"refusal_direction\": torch.rand(1536).to(torch.bfloat16)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "model = HookedTransformer.from_pretrained_no_processing(model_name, device_map=\"cuda\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"blocks.0.hook_resid_pre\",\n",
    "    \"blocks.0.ln1.hook_scale\",\n",
    "    \"blocks.0.ln1.hook_normalized\",\n",
    "    \"blocks.0.attn.hook_q\",\n",
    "    \"blocks.0.attn.hook_k\",\n",
    "    \"blocks.0.attn.hook_v\",\n",
    "    \"blocks.0.attn.hook_rot_q\",\n",
    "    \"blocks.0.attn.hook_rot_k\",\n",
    "    \"blocks.0.attn.hook_attn_scores\",\n",
    "    \"blocks.0.attn.hook_pattern\",\n",
    "    \"blocks.0.attn.hook_z\",\n",
    "    \"blocks.0.hook_attn_out\",\n",
    "    \"blocks.0.hook_resid_mid\",\n",
    "    \"blocks.0.ln2.hook_scale\",\n",
    "    \"blocks.0.ln2.hook_normalized\",\n",
    "    \"blocks.0.mlp.hook_pre\",\n",
    "    \"blocks.0.mlp.hook_pre_linear\",\n",
    "    \"blocks.0.mlp.hook_post\",\n",
    "    \"blocks.0.hook_mlp_out\",\n",
    "    \"blocks.0.hook_resid_post\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abliteration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
